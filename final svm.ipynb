{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies of each fold : [0.61875, 0.58125, 0.575, 0.55, 0.5375, 0.56875, 0.64375, 0.55625, 0.55]\n",
      "Mean Accuracy across 9 folds: 0.58\n",
      "Standard Deviation of Accuracy: 0.03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('D:\\\\ML PROJECT\\\\dataset.csv')  # Replace 'dataset.csv' with your actual file\n",
    "\n",
    "# Step 2: Preprocess the data (this is just a simple example)\n",
    "X = data.drop('target', axis=1)  # Replace 'target_column' with your actual target column name\n",
    "y = data['target']  # Assuming the target variable is in this column\n",
    "\n",
    "# Step 3: Standardize features (optional but recommended for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 4: Set up K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=9, shuffle=True, random_state=42)  # K=9\n",
    "\n",
    "# Step 5: Train and evaluate the SVM model\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create the SVM model (you can customize the hyperparameters)\n",
    "    model = SVC(C=10, gamma=0.01, kernel='rbf')  # Use your best parameters\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Step 6: Output the results\n",
    "print( 'accuracies of each fold :',accuracies)\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "\n",
    "print(f'Mean Accuracy across 9 folds: {mean_accuracy:.2f}')\n",
    "print(f'Standard Deviation of Accuracy: {std_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Accuracy: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.80      0.67        10\n",
      "           2       0.70      0.70      0.70        27\n",
      "           3       0.52      0.62      0.57        21\n",
      "           4       0.25      0.21      0.23        14\n",
      "           5       0.70      0.80      0.74        20\n",
      "           6       0.70      0.61      0.65        23\n",
      "           7       0.67      0.56      0.61        18\n",
      "           8       0.67      0.59      0.63        27\n",
      "\n",
      "    accuracy                           0.62       160\n",
      "   macro avg       0.60      0.61      0.60       160\n",
      "weighted avg       0.62      0.62      0.62       160\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.55      0.55        11\n",
      "           2       0.55      0.75      0.63        24\n",
      "           3       0.45      0.62      0.53        16\n",
      "           4       0.75      0.52      0.61        29\n",
      "           5       0.87      0.46      0.60        28\n",
      "           6       0.41      0.64      0.50        11\n",
      "           7       0.44      0.41      0.42        17\n",
      "           8       0.65      0.71      0.68        24\n",
      "\n",
      "    accuracy                           0.58       160\n",
      "   macro avg       0.58      0.58      0.57       160\n",
      "weighted avg       0.63      0.58      0.58       160\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.71      0.48         7\n",
      "           2       0.75      0.82      0.78        22\n",
      "           3       0.35      0.27      0.31        22\n",
      "           4       0.50      0.35      0.41        17\n",
      "           5       0.59      0.77      0.67        13\n",
      "           6       0.48      0.64      0.55        22\n",
      "           7       0.79      0.59      0.68        39\n",
      "           8       0.56      0.56      0.56        18\n",
      "\n",
      "    accuracy                           0.57       160\n",
      "   macro avg       0.55      0.59      0.55       160\n",
      "weighted avg       0.59      0.57      0.57       160\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.54      0.48        13\n",
      "           2       0.58      0.69      0.63        16\n",
      "           3       0.71      0.58      0.64        38\n",
      "           4       0.39      0.38      0.38        24\n",
      "           5       0.80      0.75      0.77        16\n",
      "           6       0.41      0.37      0.39        19\n",
      "           7       0.64      0.45      0.53        20\n",
      "           8       0.44      0.79      0.56        14\n",
      "\n",
      "    accuracy                           0.55       160\n",
      "   macro avg       0.55      0.57      0.55       160\n",
      "weighted avg       0.57      0.55      0.55       160\n",
      "\n",
      "Fold 5:\n",
      "Accuracy: 0.54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.33      0.40        12\n",
      "           2       0.58      0.67      0.62        21\n",
      "           3       0.47      0.45      0.46        20\n",
      "           4       0.44      0.30      0.36        23\n",
      "           5       0.72      0.72      0.72        25\n",
      "           6       0.46      0.69      0.55        16\n",
      "           7       0.52      0.55      0.53        22\n",
      "           8       0.52      0.52      0.52        21\n",
      "\n",
      "    accuracy                           0.54       160\n",
      "   macro avg       0.53      0.53      0.52       160\n",
      "weighted avg       0.53      0.54      0.53       160\n",
      "\n",
      "Fold 6:\n",
      "Accuracy: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.67      0.74        15\n",
      "           2       0.56      0.61      0.58        23\n",
      "           3       0.47      0.47      0.47        19\n",
      "           4       0.35      0.53      0.42        17\n",
      "           5       0.76      0.70      0.73        23\n",
      "           6       0.55      0.52      0.54        21\n",
      "           7       0.64      0.39      0.49        23\n",
      "           8       0.57      0.68      0.62        19\n",
      "\n",
      "    accuracy                           0.57       160\n",
      "   macro avg       0.59      0.57      0.57       160\n",
      "weighted avg       0.59      0.57      0.57       160\n",
      "\n",
      "Fold 7:\n",
      "Accuracy: 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.57      0.42         7\n",
      "           2       0.70      0.76      0.73        25\n",
      "           3       0.75      0.80      0.77        15\n",
      "           4       0.31      0.28      0.29        18\n",
      "           5       0.94      0.63      0.76        27\n",
      "           6       0.72      0.52      0.60        25\n",
      "           7       0.48      0.75      0.59        16\n",
      "           8       0.75      0.78      0.76        27\n",
      "\n",
      "    accuracy                           0.64       160\n",
      "   macro avg       0.62      0.64      0.62       160\n",
      "weighted avg       0.68      0.64      0.65       160\n",
      "\n",
      "Fold 8:\n",
      "Accuracy: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.73      0.67        11\n",
      "           2       0.74      0.74      0.74        19\n",
      "           3       0.36      0.53      0.43        17\n",
      "           4       0.56      0.39      0.46        23\n",
      "           5       0.60      0.57      0.59        21\n",
      "           6       0.47      0.50      0.48        28\n",
      "           7       0.53      0.47      0.50        17\n",
      "           8       0.68      0.62      0.65        24\n",
      "\n",
      "    accuracy                           0.56       160\n",
      "   macro avg       0.57      0.57      0.56       160\n",
      "weighted avg       0.57      0.56      0.56       160\n",
      "\n",
      "Fold 9:\n",
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.40      0.50        10\n",
      "           2       0.43      0.67      0.53        15\n",
      "           3       0.39      0.50      0.44        24\n",
      "           4       0.50      0.41      0.45        27\n",
      "           5       0.69      0.58      0.63        19\n",
      "           6       0.68      0.48      0.57        27\n",
      "           7       0.63      0.60      0.62        20\n",
      "           8       0.62      0.83      0.71        18\n",
      "\n",
      "    accuracy                           0.55       160\n",
      "   macro avg       0.58      0.56      0.55       160\n",
      "weighted avg       0.57      0.55      0.55       160\n",
      "\n",
      "\n",
      "Average Classification Report Across 9 Folds:\n",
      "Precision: 0.59, Recall: 0.58, F1-Score: 0.58\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Set up K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=9, shuffle=True, random_state=42)  # K=9\n",
    "\n",
    "# Step 5: Train and evaluate the SVM model\n",
    "fold_reports = []  # To store classification reports for each fold\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_scaled), start=1):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create the SVM model (you can customize the hyperparameters)\n",
    "    model = SVC(C=10, gamma=0.01, kernel='rbf')  # Use your best parameters\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Generate classification report for this fold\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    fold_reports.append(report)\n",
    "    \n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))  # Print the classification report\n",
    "\n",
    "# Optionally: Aggregate the classification reports if needed\n",
    "# This will help you analyze the average performance across all folds.\n",
    "avg_precision = np.mean([report['weighted avg']['precision'] for report in fold_reports])\n",
    "avg_recall = np.mean([report['weighted avg']['recall'] for report in fold_reports])\n",
    "avg_f1 = np.mean([report['weighted avg']['f1-score'] for report in fold_reports])\n",
    "\n",
    "print(\"\\nAverage Classification Report Across 9 Folds:\")\n",
    "print(f\"Precision: {avg_precision:.2f}, Recall: {avg_recall:.2f}, F1-Score: {avg_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the necessary libraries imported and your data is prepared\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize SVM model\n",
    "svm_model = svm.SVC(kernel='linear')  # You can choose the kernel based on your analysis\n",
    "\n",
    "# Perform cross-validation and get predictions\n",
    "predictions = cross_val_predict(svm_model, X, y, cv=9)\n",
    "\n",
    "# Get the classification report for Fold 1\n",
    "fold_1_predictions = predictions[y.index[train_indices]]  # Replace train_indices with the indices used for Fold 1\n",
    "fold_1_true_labels = y[y.index[train_indices]]\n",
    "\n",
    "# Print the classification report for Fold 1\n",
    "print(classification_report(fold_1_true_labels, fold_1_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
